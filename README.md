# StackExchange Data Migration to PostgreSQL

## Задача:
Перенос схемы и данных StackExchange (dba.stackexchange.org и dba.meta.stackexchange.org) из Data Dump-архивов в PostgreSQL с последующим восстановлением связей между таблицами, выполнением запросов и оптимизацией.

---

## Инструкция по запуску

Перед началом работы добавьте в корень проекта две папки с распакованными дампами:

- `meta` — содержит данные с сайта `dba.meta.stackexchange.com`. Эта папка уже находится в нужном месте.
- `main` — распакуйте дамп `dba.stackexchange.com` в эту папку.

Итоговая структура:
```
project-root/
├── main/           # дамп dba.stackexchange.com
├── meta/           # дамп dba.meta.stackexchange.com
├── fields.py
├── xml_to_csv.py
├── cleaning_files.py
├── ...
```
### Пример запуска скриптов
Скрипты удобно запускать из корневой директории проекта, чтобы не указывать полные пути до файлов.
Запуск Python файла
https://drive.google.com/drive/folders/1C3FNsLysRJbxGyegAaU0pW_XRVLxV0z_?hl=ru

Запуск SQL файла
https://drive.google.com/drive/folders/1C3FNsLysRJbxGyegAaU0pW_XRVLxV0z_?hl=ru

### Порядок запуска скриптов:

1. **`fields.py`**  
   Проверяет, какие поля реально присутствуют в XML-файлах дампа, чтобы при создании схемы учесть только нужные столбцы. Выводит список актуальных полей по каждой таблице.

2. **`xml_to_csv.py`**  
   Преобразует XML-файлы в CSV-формат. Это позволяет в дальнейшем использовать команду `COPY` для быстрой загрузки данных в PostgreSQL. Новые файлы помещаются в папку `output`, которая будет создана автоматически.

3. **`cleaning_files.py`**  
   Проверяет соответствие данных заявленным первичным и внешним ключам.  
   Скрипт создаёт очищенные версии CSV-файлов с суффиксом `_cleaning`.  
   Оригинальные файлы удаляются для экономии места на диске.

После выполнения этих шагов можно переходить к созданию схемы и загрузке данных в базу.

4. **`create_schema.sql`**  
   Создаёт схему базы данных на основе таблиц, реально присутствующих в дампе.  
   На этом этапе **не накладываются первичные и внешние ключи**, чтобы ускорить массовую вставку данных.

5. **`data_import.sql`**  
   Загружает очищенные CSV-файлы в базу данных с помощью команды `COPY`.  
   Файлы берутся из папки `output`, и должны иметь суффикс `_cleaning.csv`.

6. **`table_keys.sql`**  
   После загрузки данных задаёт первичные и внешние ключи для всех таблиц, устанавливая связи между ними.

7. **`table_PostTags_and_indexes.sql`**  
   - Создаёт и заполняет таблицу `PostTags`, которая реализует связь "многие-ко-многим" между таблицами `Posts` и `Tags`.
   - Создаёт индексы:
     - На внешние ключи для ускорения JOIN и каскадных операций.
     - На поля, которые активно используются в конкретных запросах **Q1** и **Q2** (детали будут рассмотрены далее).
