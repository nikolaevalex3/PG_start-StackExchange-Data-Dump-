# StackExchange Data Migration to PostgreSQL

## Задача:
Перенос схемы и данных StackExchange (dba.stackexchange.org и dba.meta.stackexchange.org) из Data Dump-архивов в PostgreSQL с последующим восстановлением связей между таблицами, выполнением запросов и оптимизацией.

---

## Инструкция по запуску

Перед началом работы добавьте в корень проекта две папки с распакованными дампами:

- `meta` — содержит данные с сайта `dba.meta.stackexchange.com`. Эта папка уже находится в нужном месте.
- `main` — распакуйте дамп `dba.stackexchange.com` в эту папку.

Итоговая структура:
```
project-root/
├── main/           # дамп dba.stackexchange.com
├── meta/           # дамп dba.meta.stackexchange.com
├── fields.py
├── xml_to_csv.py
├── cleaning_files.py
├── ...
```
### Пример запуска скриптов
Скрипты удобно запускать из корневой директории проекта.

Запуск Python файла:

![Запуск Python файла](images/python_example.png)

Запуск SQL файла:

![Запуск SQL файла](images/sql_example.png)


### Порядок запуска скриптов:

1. **`fields.py`**  
   Проверяет, какие поля реально присутствуют в XML-файлах дампа, чтобы при создании схемы учесть только нужные столбцы. Выводит список актуальных полей по каждой таблице. Не забудьте про requirements.txt

2. **`xml_to_csv.py`**  
   Преобразует XML-файлы в CSV-формат. Это позволяет в дальнейшем использовать команду `COPY` для быстрой загрузки данных в PostgreSQL. Новые файлы помещаются в папку `output`, которая будет создана автоматически.

3. **`cleaning_files.py`**  
   Проверяет соответствие данных заявленным первичным и внешним ключам.  
   Скрипт создаёт очищенные версии CSV-файлов с суффиксом `_cleaning`.  
   Оригинальные файлы удаляются для экономии места на диске.

После выполнения этих шагов можно переходить к созданию схемы и загрузке данных в базу.

4. **`create_schema.sql`**  
   Создаёт схему базы данных на основе таблиц, реально присутствующих в дампе.  
   На этом этапе **не накладываются первичные и внешние ключи**, чтобы ускорить массовую вставку данных.

5. **`data_import.sql`**  
   Загружает очищенные CSV-файлы в базу данных с помощью команды `COPY`.  
   Файлы берутся из папки `output`, и должны иметь суффикс `_cleaning.csv`.

6. **`table_keys.sql`**  
   После загрузки данных задаёт первичные и внешние ключи для всех таблиц, устанавливая связи между ними.

7. **`table_PostTags_and_indexes.sql`**  
   - Создаёт и заполняет таблицу `PostTags`, которая реализует связь "многие-ко-многим" между таблицами `Posts` и `Tags`.
   - Создаёт индексы:
     - На внешние ключи для ускорения JOIN и каскадных операций.
     - На поля, которые активно используются в конкретных запросах **Q1** и **Q2** (детали будут рассмотрены далее).

После этого можно перейти к запросам Q1 и Q2. Их можно выполнять в любом порядке.

## Аппаратная и программная среда

Перед тем как перейти к выполнению SQL-запросов, рассмотрим используемую среду выполнения:

- **PostgreSQL 16**
- Установлен на виртуальной машине
- **Оперативная память:** 2 ГБ
- **Хранилище:** SSD ноутбука, доступ через **виртуальный диск (SATA)**

---

## Рекомендованная конфигурация PostgreSQL

Чтобы PostgreSQL эффективно работал в условиях ограниченных ресурсов (2 ГБ ОЗУ), в `postgresql.conf` стоит задать следующие параметры:

```conf
# Общая память
shared_buffers = 512MB              # ~25% от доступной RAM, используемой PostgreSQL
work_mem = 8MB                      # Немного увеличим память на каждую операцию сортировки/хэша в запросах
maintenance_work_mem = 128MB       # Используется при ANALYZE, VACUUM, создании индексов

# Параметры записи WAL
wal_buffers = 16MB
min_wal_size = 512MB
max_wal_size = 1GB                 # Увеличим, чтобы растянуть процесс записи большого объёма новых данных на более продолжительное время

# Параметры параллелизма
max_parallel_workers = 2           # Полезно при аналитических запросах
parallel_setup_cost = 1000         # Уменьшено, чтобы чаще использовать параллельные планы
parallel_tuple_cost = 0.1

# Автоочистка
autovacuum = on
autovacuum_naptime = 1min

effective_cache_size = 1536MB     # 75% RAM. Указывает планировщику запросов, сколько памяти может быть кэшировано системой. Повышает вероятность выбора индексов.

SET random_page_cost = 1.5        # Для SSD рекомендуемое значение около 1, но так как у меня доступ к SSD через Виртуальный SATA-диск, то 1.5 будет компромисным значением.
```

Параметры подобраны для сбалансированной работы PostgreSQL в условиях ограниченных ресурсов.

##  Индексы

Для ускорения выполнения `JOIN`-операций и каскадных удалений были созданы **индексы на внешние ключи**. В некоторых случаях применялись **частичные индексы**, например:

```sql
CREATE INDEX IF NOT EXISTS idx_posts_acceptedanswerid
ON stackexchange_data.posts(AcceptedAnswerId)
WHERE AcceptedAnswerId IS NOT NULL;
```

Такое решение принималось после анализа статистики — если в столбце много `NULL`, и эти NULL-значения логически не участвуют в запросах, то **частичный индекс** экономит место и повышает производительность.

Также при проектировании структуры индексов я придерживался принципа:

> *Суммарный объём всех индексов по таблице не должен превышать половину её объёма.*

Это помогает избежать **засорения таблицы** лишними индексами, которые редко используются.

---

### Особые индексы

Некоторые индексы были созданы **не только на внешние ключи**, а под конкретные сценарии использования:

1. **Индекс по `Score` в `Posts`**

```sql
CREATE INDEX IF NOT EXISTS idx_posts_score
ON stackexchange_data.posts(score);
```

Этот индекс используется для **сортировок и фильтраций по рейтингу**, что является довольно частым сценарием.

---

2. **GIN-индекс по полю `Tags` с использованием `pg_trgm`**

```sql
CREATE EXTENSION IF NOT EXISTS pg_trgm;

CREATE INDEX IF NOT EXISTS tags_trgm_idx
ON stackexchange_data.posts
USING GIN (tags gin_trgm_ops);
```

Этот индекс помогает при **поиске по частичному совпадению в поле `Tags`**, например:

```sql
WHERE tags LIKE '%postgresql%'
```

> Практика показала, что фильтрация по подстроке в тегах — может быть востребованной операцией. Этот индекс существенно улучшает время отклика таких запросов.
---

3. **Индексы для таблицы `PostTags`**

```sql
CREATE INDEX IF NOT EXISTS idx_posttags_postid_tagid
ON stackexchange_data.posttags(PostId, TagId);

CREATE INDEX IF NOT EXISTS idx_posttags_tagid
ON stackexchange_data.posttags(TagId);
```

- **Составной индекс `PostId, TagId`** используется при фильтрации по **обеим колонкам одновременно**, что типично при анализе связей между постами и тегами.
- **Одиночный индекс по `TagId`** полезен, когда запросы обращаются **только к тегам** (например, выбор всех постов с определённым тегом без знания `PostId`). Обратный случай уже покрывает составной индекс, где `PostId` указан первым.

4. **Индекс по `PostTypeId` в `Posts`**
```sql
CREATE INDEX IF NOT EXISTS idx_posts_posttypeid ON stackexchange_data.posts (posttypeid);
```

Этот индекс будет использоваться при работе с типами постов. Популярный фильтр. Наиболее часто для вопросов и ответов, которые занимают 99% этого столбца. 

Все созданные индексы описаны в файле [`table_PostTags_and_indexes.sql`](scripts/table_PostTags_and_indexes.sql) и применяются в практических задачах, включая `Q1` и `Q2`.


## Q1 — "Репутационные пары"

### Условие задачи

Запрос анализирует, какие теги задаются одновременно, как быстро на них отвечают и как это связано с репутацией пользователей.  
Он выполняет следующие действия:

- Находит **пары тегов**, которые **часто встречаются вместе** в вопросах.
- В выборку попадают **только вопросы с тегом `postgresql`**.
- Определяет **среднее время ответа** на такие вопросы.
- Сопоставляет ответы с **репутацией пользователей**, которые их дали.

---

### Логика запроса

Первый созданный SQL-запрос находится в файле [`Q1_with_PostTags.sql`](scripts/Q1_with_PostTags.sql).

- Запрос объединяет таблицы `Posts`, `PostTags`, `Tags`, `Users`, чтобы получить все нужные данные.
- Через `JOIN` создаются пары тегов, исключая сам `postgresql`, так как:
  > *«Хотя это явно не было сказано в задании, мне показалось логичным исключить тег `postgresql` из итоговых пар, так как он обязателен по условию.»*
- Используется группировка по парам тегов, и считаются:
  - Количество таких вопросов
  - Среднее время ответа
  - Средняя репутация авторов ответов

---

### Оптимизация и индексы

План запроса показывает, что он **эффективно использует имеющиеся индексы**, особенно радуют индексы на таблице `PostTags`:

```text
->  Index Only Scan using idx_posttags_postid_tagid on posttags pt2
->  Parallel Index Only Scan using idx_posttags_postid_tagid on posttags pt1
```

Тем не менее, **время выполнения остаётся заметным** из-за большого количества `JOIN`, даже с учётом того, что они покрыты индексами. Этого можно было ожидать при работе с большими таблицами, особенно при создании попарных сочетаний тегов.

---

## Альтернативный подход

Для ускорения было принято решение **избежать `JOIN`-ов**, и работать напрямую с таблицей `Posts`, где теги хранятся как строка с разделителем `"|"`.

- Несмотря на то, что **формат хранения неудобен для анализа**, он позволяет **сократить количество соединений**.
- Пары тегов извлекались с помощью `CROSS JOIN LATERAL`, `string_to_array` и `unnest`.

> Этот вариант запроса находится в файле [`Q1_with_LIKE.sql`](scripts/Q1_with_LIKE.sql)

---

## Сравнение производительности

Для объективного сравнения вариантов был создан тестовый скрипт [`Q1_comparison.sql`](scripts/Q1_comparison.sql), который запускал оба запроса и замерял время.

**Результаты без дополнительной оптимизации с горячим кэшом**: `Q1_with_PostTags.sql` — немного быстрее.
При холодном кэше запросы показвали одиаковый результат, так как отсутствие данных в кэше сильнее било по запросу, где к кэшу больше обращений.

---

## 🔧 Оптимизация `Q1_with_LIKE.sql`

Проблемный участок запроса — **фильтрация по строковому полю `Tags`**. Оно не индексировалось, что снижало производительность.

Решение:
```sql
CREATE EXTENSION IF NOT EXISTS pg_trgm;

CREATE INDEX IF NOT EXISTS tags_trgm_idx
ON stackexchange_data.posts
USING GIN (tags gin_trgm_ops);
```

После создания GIN-индекса с `pg_trgm` повторное тестирование показало, что **Запрос `Q1_with_LIKE.sql` стал выполняться быстрее на ~50 мс** по сравнению с вариантом с многочисленными JOIN'ами.

Это делает его **предпочтительным**.

**Планы запросов будут выведены вместе с самими запросами при запуске скрипта. Но также их можно увидеть в файле QUERY_PLANS.pdf**


## Q2 — "Успешные шутники"

### Условие задачи
Найти ответы с самыми низкими оценками, которые были приняты как лучший ответ, это что-то вроде "парада парадоксов", где авторы приняли ответ, несмотря на низкий рейтинг
- ищем только те ответы, которые были приняты авторами вопросов (`AcceptedAnswerId`), даже если они имеют низкий рейтинг (`Score < 0`)
- добавляется имя пользователя, который дал ответ
- cортируем ответы по худшему рейтингу
- ответ должен иметь тег `postgresql`

---

### Логика запроса

Запрос реализован в файле [`Q2_unloved_but_accepted.sql`](scripts/Q2.sql). 

Он "в лоб" присоединяет все необходимые таблицы:
- `Posts` — для получения вопросов и ответов (ответы присоединяются по условию q.acceptedanswerid = a.id)
- `Users` — чтобы получить имена авторов
- `PostTags` — для фильтрации по тегу `postgresql`

После присоединения выполняется фильтрация:
- Вопрос содержит тег `postgresql`
- Оценка ответа (`Score`) меньше нуля

Далее происходит сортировка и LIMIT.

---

### Производительность

Запрос эффективно использует созданные индексы:

- Индекс по `PostTags(PostId, TagId)` — для фильтрации по тегу
- Индекс по `AcceptedAnswerId` — для соединения вопросов с ответами
- Индекс по `Posts.Score` — помогает при сортировке

Благодаря хорошей логике запроса, корректным индексам и правильной схеме, выполнение запроса происходит быстро даже при большом объёме.
По аналогии с запросом Q1 была предпринята попытка фильтровать тэги из таблицы Posts, но в этот раз такой подход ожидаемо оказался проигрышным, так как не был такого большого количества JOIN'ов, которых надо было избежать.
